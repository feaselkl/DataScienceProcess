{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data Science Process\n",
    "\n",
    "This is intended to be a follow-up script for my talk entitled [Cleaning is Half the Battle:  Launching a Data Science Project](http://www.catallaxyservices.com/presentations/datascience/).  I will repeat some of the presentation in this notebook, but this notebook is not designed to replace the presentation itself.\n",
    "\n",
    "Over the course of this notebook, we will analyze Data Professional salaries based on the [2018 Data Professionals Salary Survey](https://www.brentozar.com/archive/2018/01/2018-data-professionals-salary-survey-results/).  We will use this data as the centerpiece of an implementation of the [Microsoft Team Data Science Process](https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/overview).\n",
    "\n",
    "The Team Data Science Process has five major steps:\n",
    "1. Business Understanding\n",
    "2. Data Processing\n",
    "3. Modeling\n",
    "4. Deployment\n",
    "5. Repeat\n",
    "\n",
    "## Business Understanding\n",
    "\n",
    "Before we begin working, we need to understand the problem.  In our scenario, we work for Data Platform Specialists, a company dedicated to providing DBAs and other data platform professionals with valuable market knowledge. We have come into possession of a survey of data professionals and want to build insights that we can share with our client base.  Our higher-ups want us to analyze this survey and see how we can make good use of it.\n",
    "\n",
    "During initial brainstorming, we might come up with questions like:\n",
    "* How much money does a DBA make?\n",
    "* Which category of DBA (junior, mid-level, senior) does this particular work?\n",
    "* How can we segment the DBAs in our survey?\n",
    "* Is this many hours per week weird?\n",
    "* Which option should I choose as a career path? DBA? Data science? BI?\n",
    "\n",
    "These questions could potentially be interesting, and the specific form of the question will help guide our analysis.  For example, \"how much\" questions typically lead to regression, whereas \"which category\" questions are indicative of a classification problem.  Segmentation questions where we do not know the classes beforehand is a classic example of a clustering problem, and the final two questions are anomaly detection and recommendation, respectively.\n",
    "\n",
    "Narrowing this down with our champion and other stakeholders, we can get to the following question which we will endeavour to answer:\n",
    "\n",
    "**How much money should we expect a data professional will make?**\n",
    "\n",
    "This is a vague question that we will want to focus in on later, but at least it gives us a start.\n",
    "\n",
    "## Data Processing\n",
    "\n",
    "There are three steps to data processing:  data gathering, data cleansing, and data analysis.\n",
    "\n",
    "### Data Gathering\n",
    "\n",
    "In this example, we will stick to just the data professional survey. But if you want to take this further, a few additional data sources could be:\n",
    "\n",
    "* PPP GDP per capita to normalize salaries across countries.\n",
    "* A geocoding data set to visualize results on a map.\n",
    "* Cost of living by ZIP code to normalize salaries within the US.\n",
    "* Census information to build out data by ZIP code.\n",
    "* Data from other surveys to add more to the sample.\n",
    "\n",
    "If you are interested in extending this to include PPP GDP per capita, check out [a blog post I did based on the 2017 survey results](https://36chambers.wordpress.com/2017/01/18/analyzing-dba-salaries/).\n",
    "\n",
    "### Data Cleansing\n",
    "\n",
    "Here is where we begin the real work.  In the next snippet, I am going to load a series of libraries in R.  We will use each of them over the course of this notebook.  The `tidyverse` package is a series of incredibly useful libraries in R, and I can't think of doing a data science project in R without it.  The `XLConnect` package lets me read an Excel workbook easily and grab the salary data without much hassle.  The `caret` library provides some helpful tooling for working with data, including splitting out test versus training data, like we'll do below.  The `recipes` package will be useful for normalizing data later, and we will use `data.table` to get a glimpse at some of our uneven data.  We need the `devtools` package to install `keras` from GitHub.  Keras is a deep learning library which implements several neural network libraries, including TensorFlow, which we are using today.  We need to install TensorFlow on our machine.  Because this is a small data set, and because I want this to run on machines without powerful GPUs, I am using the CPU-based version of TensorFlow.  Performance should still be adequate for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: tidyverse\n",
      "Loading tidyverse: ggplot2\n",
      "Loading tidyverse: tibble\n",
      "Loading tidyverse: tidyr\n",
      "Loading tidyverse: readr\n",
      "Loading tidyverse: purrr\n",
      "Loading tidyverse: dplyr\n",
      "Conflicts with tidy packages ---------------------------------------------------\n",
      "filter(): dplyr, stats\n",
      "lag():    dplyr, stats\n",
      "Loading required package: XLConnect\n",
      "Warning message:\n",
      "\"package 'XLConnect' was built under R version 3.4.3\"Loading required package: XLConnectJars\n",
      "Warning message:\n",
      "\"package 'XLConnectJars' was built under R version 3.4.3\"XLConnect 0.2-14 by Mirai Solutions GmbH [aut],\n",
      "  Martin Studer [cre],\n",
      "  The Apache Software Foundation [ctb, cph] (Apache POI),\n",
      "  Graph Builder [ctb, cph] (Curvesapi Java library)\n",
      "http://www.mirai-solutions.com\n",
      "https://github.com/miraisolutions/xlconnect\n",
      "Loading required package: caret\n",
      "Warning message:\n",
      "\"package 'caret' was built under R version 3.4.3\"Loading required package: lattice\n",
      "\n",
      "Attaching package: 'caret'\n",
      "\n",
      "The following object is masked from 'package:purrr':\n",
      "\n",
      "    lift\n",
      "\n",
      "Loading required package: recipes\n",
      "Warning message:\n",
      "\"package 'recipes' was built under R version 3.4.3\"Loading required package: broom\n",
      "\n",
      "Attaching package: 'recipes'\n",
      "\n",
      "The following object is masked from 'package:stats':\n",
      "\n",
      "    step\n",
      "\n",
      "Loading required package: data.table\n",
      "\n",
      "Attaching package: 'data.table'\n",
      "\n",
      "The following objects are masked from 'package:dplyr':\n",
      "\n",
      "    between, first, last\n",
      "\n",
      "The following object is masked from 'package:purrr':\n",
      "\n",
      "    transpose\n",
      "\n",
      "Loading required package: devtools\n",
      "\n",
      "Attaching package: 'devtools'\n",
      "\n",
      "The following object is masked from 'package:recipes':\n",
      "\n",
      "    check\n",
      "\n",
      "Loading required package: keras\n"
     ]
    }
   ],
   "source": [
    "if(!require(tidyverse)) {\n",
    "  install.packages(\"tidyverse\", repos = \"http://cran.us.r-project.org\")\n",
    "  library(tidyverse)\n",
    "}\n",
    "\n",
    "if(!require(XLConnect)) {\n",
    "  install.packages(\"XLConnect\", repos = \"http://cran.us.r-project.org\")\n",
    "  library(XLConnect)\n",
    "}\n",
    "\n",
    "if(!require(caret)) {\n",
    "  install.packages(\"caret\", repos = \"http://cran.us.r-project.org\")\n",
    "  library(caret)\n",
    "}\n",
    "\n",
    "if(!require(recipes)) {\n",
    "  install.packages(\"recipes\", repos = \"http://cran.us.r-project.org\")\n",
    "  library(caret)\n",
    "}\n",
    "\n",
    "if(!require(data.table)) {\n",
    "  install.packages(\"data.table\", repos = \"http://cran.us.r-project.org\")\n",
    "  library(data.table)\n",
    "}\n",
    "\n",
    "if(!require(devtools)) {\n",
    "  install.packages(\"devtools\", repos = \"http://cran.us.r-project.org\")\n",
    "  library(devtools)\n",
    "}\n",
    "\n",
    "if(!require(keras)) {\n",
    "  devtools::install_github(\"rstudio/keras\")\n",
    "  library(keras)\n",
    "  install_keras(method = \"auto\", conda = \"auto\", tensorflow = \"default\", extra_packages = NULL)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the required packages loaded, we will then load the Excel workbook.  I have verified the Excel worksheet and data region are correct, so we can grab the survey from the current directory and load it into `salary_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb <- XLConnect::loadWorkbook(\"2018_Data_Professional_Salary_Survey_Responses.xlsx\")\n",
    "salary_data <- XLConnect::readWorksheet(wb, sheet = \"Salary Survey\", region = \"A4:Z6015\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `glimpse` function inside the tidyverse to get a quick idea of what our `salary_data` dataframe looks like.  In total, we have 6011 observations of 26 variables, but this covers two survey years:  2017 and 2018.  Looking at the variable names, we can see that there are some which don't matter very much (like Timestamp, which is when the user filled out the form; and Counter, which is just a 1 for each record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glimpse(salary_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first data cleansing activity will be to filter our data to include just 2018 results, which gives us a sample size of 3,113 participants.  There are also results for 2017, but they asked a different set of questions and we don't want to complicate the analysis or strip out the new 2018 questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "3113"
      ],
      "text/latex": [
       "3113"
      ],
      "text/markdown": [
       "3113"
      ],
      "text/plain": [
       "[1] 3113"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "survey_2018 <- filter(salary_data, Survey.Year == 2018)\n",
    "nrow(survey_2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the survey, there are some interesting data points that we want:\n",
    "* SalaryUSD (our label, that is, what we are going to try to predict)\n",
    "* Country\n",
    "* YearsWithThisDatabase\n",
    "* EmploymentStatus\n",
    "* JobTitle\n",
    "* ManageStaff\n",
    "* YearsWithThisTypeOfJob\n",
    "* OtherPeopleOnYourTeam\n",
    "* DatabaseServers\n",
    "* Education\n",
    "* EducationIsComputerRelated\n",
    "* Certifications\n",
    "* HoursWorkedPerWeek\n",
    "* TelecommuteDaysPerWeek\n",
    "* EmploymentSector\n",
    "* LookingForAnotherJob\n",
    "* CareerPlansThisYear\n",
    "* Gender\n",
    "\n",
    "For each of these variables, we want to see the range of options and perform any necessary cleanup.  The first thing I'd look at is the cardinality of each variable, followed by a detailed anlaysis of the smaller ones.\n",
    "\n",
    "PrimaryDatabase is another variable which looks interesting, but it skews so heavily toward SQL Server that there's more noise than signal to it.  Because there are so many platforms with 10 or fewer entries and about 92% of entrants selected SQL Server, we'll throw it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Survey.Year</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>Timestamp</dt>\n",
       "\t\t<dd>3112</dd>\n",
       "\t<dt>SalaryUSD</dt>\n",
       "\t\t<dd>865</dd>\n",
       "\t<dt>Country</dt>\n",
       "\t\t<dd>73</dd>\n",
       "\t<dt>PostalCode</dt>\n",
       "\t\t<dd>1947</dd>\n",
       "\t<dt>PrimaryDatabase</dt>\n",
       "\t\t<dd>14</dd>\n",
       "\t<dt>YearsWithThisDatabase</dt>\n",
       "\t\t<dd>38</dd>\n",
       "\t<dt>OtherDatabases</dt>\n",
       "\t\t<dd>746</dd>\n",
       "\t<dt>EmploymentStatus</dt>\n",
       "\t\t<dd>4</dd>\n",
       "\t<dt>JobTitle</dt>\n",
       "\t\t<dd>12</dd>\n",
       "\t<dt>ManageStaff</dt>\n",
       "\t\t<dd>2</dd>\n",
       "\t<dt>YearsWithThisTypeOfJob</dt>\n",
       "\t\t<dd>39</dd>\n",
       "\t<dt>OtherPeopleOnYourTeam</dt>\n",
       "\t\t<dd>7</dd>\n",
       "\t<dt>DatabaseServers</dt>\n",
       "\t\t<dd>177</dd>\n",
       "\t<dt>Education</dt>\n",
       "\t\t<dd>5</dd>\n",
       "\t<dt>EducationIsComputerRelated</dt>\n",
       "\t\t<dd>3</dd>\n",
       "\t<dt>Certifications</dt>\n",
       "\t\t<dd>3</dd>\n",
       "\t<dt>HoursWorkedPerWeek</dt>\n",
       "\t\t<dd>49</dd>\n",
       "\t<dt>TelecommuteDaysPerWeek</dt>\n",
       "\t\t<dd>6</dd>\n",
       "\t<dt>EmploymentSector</dt>\n",
       "\t\t<dd>7</dd>\n",
       "\t<dt>LookingForAnotherJob</dt>\n",
       "\t\t<dd>3</dd>\n",
       "\t<dt>CareerPlansThisYear</dt>\n",
       "\t\t<dd>5</dd>\n",
       "\t<dt>Gender</dt>\n",
       "\t\t<dd>21</dd>\n",
       "\t<dt>OtherJobDuties</dt>\n",
       "\t\t<dd>484</dd>\n",
       "\t<dt>KindsOfTasksPerformed</dt>\n",
       "\t\t<dd>204</dd>\n",
       "\t<dt>Counter</dt>\n",
       "\t\t<dd>1</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Survey.Year] 1\n",
       "\\item[Timestamp] 3112\n",
       "\\item[SalaryUSD] 865\n",
       "\\item[Country] 73\n",
       "\\item[PostalCode] 1947\n",
       "\\item[PrimaryDatabase] 14\n",
       "\\item[YearsWithThisDatabase] 38\n",
       "\\item[OtherDatabases] 746\n",
       "\\item[EmploymentStatus] 4\n",
       "\\item[JobTitle] 12\n",
       "\\item[ManageStaff] 2\n",
       "\\item[YearsWithThisTypeOfJob] 39\n",
       "\\item[OtherPeopleOnYourTeam] 7\n",
       "\\item[DatabaseServers] 177\n",
       "\\item[Education] 5\n",
       "\\item[EducationIsComputerRelated] 3\n",
       "\\item[Certifications] 3\n",
       "\\item[HoursWorkedPerWeek] 49\n",
       "\\item[TelecommuteDaysPerWeek] 6\n",
       "\\item[EmploymentSector] 7\n",
       "\\item[LookingForAnotherJob] 3\n",
       "\\item[CareerPlansThisYear] 5\n",
       "\\item[Gender] 21\n",
       "\\item[OtherJobDuties] 484\n",
       "\\item[KindsOfTasksPerformed] 204\n",
       "\\item[Counter] 1\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Survey.Year\n",
       ":   1Timestamp\n",
       ":   3112SalaryUSD\n",
       ":   865Country\n",
       ":   73PostalCode\n",
       ":   1947PrimaryDatabase\n",
       ":   14YearsWithThisDatabase\n",
       ":   38OtherDatabases\n",
       ":   746EmploymentStatus\n",
       ":   4JobTitle\n",
       ":   12ManageStaff\n",
       ":   2YearsWithThisTypeOfJob\n",
       ":   39OtherPeopleOnYourTeam\n",
       ":   7DatabaseServers\n",
       ":   177Education\n",
       ":   5EducationIsComputerRelated\n",
       ":   3Certifications\n",
       ":   3HoursWorkedPerWeek\n",
       ":   49TelecommuteDaysPerWeek\n",
       ":   6EmploymentSector\n",
       ":   7LookingForAnotherJob\n",
       ":   3CareerPlansThisYear\n",
       ":   5Gender\n",
       ":   21OtherJobDuties\n",
       ":   484KindsOfTasksPerformed\n",
       ":   204Counter\n",
       ":   1\n",
       "\n"
      ],
      "text/plain": [
       "               Survey.Year                  Timestamp \n",
       "                         1                       3112 \n",
       "                 SalaryUSD                    Country \n",
       "                       865                         73 \n",
       "                PostalCode            PrimaryDatabase \n",
       "                      1947                         14 \n",
       "     YearsWithThisDatabase             OtherDatabases \n",
       "                        38                        746 \n",
       "          EmploymentStatus                   JobTitle \n",
       "                         4                         12 \n",
       "               ManageStaff     YearsWithThisTypeOfJob \n",
       "                         2                         39 \n",
       "     OtherPeopleOnYourTeam            DatabaseServers \n",
       "                         7                        177 \n",
       "                 Education EducationIsComputerRelated \n",
       "                         5                          3 \n",
       "            Certifications         HoursWorkedPerWeek \n",
       "                         3                         49 \n",
       "    TelecommuteDaysPerWeek           EmploymentSector \n",
       "                         6                          7 \n",
       "      LookingForAnotherJob        CareerPlansThisYear \n",
       "                         3                          5 \n",
       "                    Gender             OtherJobDuties \n",
       "                        21                        484 \n",
       "     KindsOfTasksPerformed                    Counter \n",
       "                       204                          1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rapply(survey_2018, function(x) { length(unique(x)) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'United States'</li>\n",
       "\t<li>'Australia'</li>\n",
       "\t<li>'Spain'</li>\n",
       "\t<li>'United Kingdom'</li>\n",
       "\t<li>'Canada'</li>\n",
       "\t<li>'Romania'</li>\n",
       "\t<li>'Brazil'</li>\n",
       "\t<li>'Croatia'</li>\n",
       "\t<li>'Sweden'</li>\n",
       "\t<li>'Belgium'</li>\n",
       "\t<li>'Italy'</li>\n",
       "\t<li>'Netherlands'</li>\n",
       "\t<li>'Denmark'</li>\n",
       "\t<li>'Poland'</li>\n",
       "\t<li>'Germany'</li>\n",
       "\t<li>'Russia'</li>\n",
       "\t<li>'Syria'</li>\n",
       "\t<li>'India'</li>\n",
       "\t<li>'South Africa'</li>\n",
       "\t<li>'Hong Kong'</li>\n",
       "\t<li>'United Arab Emirates'</li>\n",
       "\t<li>'Switzerland'</li>\n",
       "\t<li>'Ireland'</li>\n",
       "\t<li>'France'</li>\n",
       "\t<li>'Jersey'</li>\n",
       "\t<li>'Austria'</li>\n",
       "\t<li>'New Zealand'</li>\n",
       "\t<li>'Norway'</li>\n",
       "\t<li>'Costa Rica'</li>\n",
       "\t<li>'Mexico'</li>\n",
       "\t<li>'Greece'</li>\n",
       "\t<li>'Serbia and Montenegro'</li>\n",
       "\t<li>'Cayman Islands'</li>\n",
       "\t<li>'Philippines'</li>\n",
       "\t<li>'Indonesia'</li>\n",
       "\t<li>'Slovenia'</li>\n",
       "\t<li>'Bulgaria'</li>\n",
       "\t<li>'Guernsey'</li>\n",
       "\t<li>'Iceland'</li>\n",
       "\t<li>'Hungary'</li>\n",
       "\t<li>'Bahrain'</li>\n",
       "\t<li>'Thailand'</li>\n",
       "\t<li>'Turkey'</li>\n",
       "\t<li>'Moldova'</li>\n",
       "\t<li>'Nicaragua'</li>\n",
       "\t<li>'Lithuania'</li>\n",
       "\t<li>'Portugal'</li>\n",
       "\t<li>'Argentina'</li>\n",
       "\t<li>'Finland'</li>\n",
       "\t<li>'Israel'</li>\n",
       "\t<li>'Slovakia'</li>\n",
       "\t<li>'Pakistan'</li>\n",
       "\t<li>'Luxembourg'</li>\n",
       "\t<li>'Jamaica'</li>\n",
       "\t<li>'Ukraine'</li>\n",
       "\t<li>'Malta'</li>\n",
       "\t<li>'Czech Republic'</li>\n",
       "\t<li>'Colombia'</li>\n",
       "\t<li>'Singapore'</li>\n",
       "\t<li>'Jordan'</li>\n",
       "\t<li>'Uganda'</li>\n",
       "\t<li>'Belarus'</li>\n",
       "\t<li>'Estonia'</li>\n",
       "\t<li>'Puerto Rico'</li>\n",
       "\t<li>'Saudi Arabia'</li>\n",
       "\t<li>'Latvia'</li>\n",
       "\t<li>'Malaysia'</li>\n",
       "\t<li>'Nepal'</li>\n",
       "\t<li>'Ghana'</li>\n",
       "\t<li>'Dominican Republic'</li>\n",
       "\t<li>'Uruguay'</li>\n",
       "\t<li>'Guatemala'</li>\n",
       "\t<li>'El Salvador'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'United States'\n",
       "\\item 'Australia'\n",
       "\\item 'Spain'\n",
       "\\item 'United Kingdom'\n",
       "\\item 'Canada'\n",
       "\\item 'Romania'\n",
       "\\item 'Brazil'\n",
       "\\item 'Croatia'\n",
       "\\item 'Sweden'\n",
       "\\item 'Belgium'\n",
       "\\item 'Italy'\n",
       "\\item 'Netherlands'\n",
       "\\item 'Denmark'\n",
       "\\item 'Poland'\n",
       "\\item 'Germany'\n",
       "\\item 'Russia'\n",
       "\\item 'Syria'\n",
       "\\item 'India'\n",
       "\\item 'South Africa'\n",
       "\\item 'Hong Kong'\n",
       "\\item 'United Arab Emirates'\n",
       "\\item 'Switzerland'\n",
       "\\item 'Ireland'\n",
       "\\item 'France'\n",
       "\\item 'Jersey'\n",
       "\\item 'Austria'\n",
       "\\item 'New Zealand'\n",
       "\\item 'Norway'\n",
       "\\item 'Costa Rica'\n",
       "\\item 'Mexico'\n",
       "\\item 'Greece'\n",
       "\\item 'Serbia and Montenegro'\n",
       "\\item 'Cayman Islands'\n",
       "\\item 'Philippines'\n",
       "\\item 'Indonesia'\n",
       "\\item 'Slovenia'\n",
       "\\item 'Bulgaria'\n",
       "\\item 'Guernsey'\n",
       "\\item 'Iceland'\n",
       "\\item 'Hungary'\n",
       "\\item 'Bahrain'\n",
       "\\item 'Thailand'\n",
       "\\item 'Turkey'\n",
       "\\item 'Moldova'\n",
       "\\item 'Nicaragua'\n",
       "\\item 'Lithuania'\n",
       "\\item 'Portugal'\n",
       "\\item 'Argentina'\n",
       "\\item 'Finland'\n",
       "\\item 'Israel'\n",
       "\\item 'Slovakia'\n",
       "\\item 'Pakistan'\n",
       "\\item 'Luxembourg'\n",
       "\\item 'Jamaica'\n",
       "\\item 'Ukraine'\n",
       "\\item 'Malta'\n",
       "\\item 'Czech Republic'\n",
       "\\item 'Colombia'\n",
       "\\item 'Singapore'\n",
       "\\item 'Jordan'\n",
       "\\item 'Uganda'\n",
       "\\item 'Belarus'\n",
       "\\item 'Estonia'\n",
       "\\item 'Puerto Rico'\n",
       "\\item 'Saudi Arabia'\n",
       "\\item 'Latvia'\n",
       "\\item 'Malaysia'\n",
       "\\item 'Nepal'\n",
       "\\item 'Ghana'\n",
       "\\item 'Dominican Republic'\n",
       "\\item 'Uruguay'\n",
       "\\item 'Guatemala'\n",
       "\\item 'El Salvador'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'United States'\n",
       "2. 'Australia'\n",
       "3. 'Spain'\n",
       "4. 'United Kingdom'\n",
       "5. 'Canada'\n",
       "6. 'Romania'\n",
       "7. 'Brazil'\n",
       "8. 'Croatia'\n",
       "9. 'Sweden'\n",
       "10. 'Belgium'\n",
       "11. 'Italy'\n",
       "12. 'Netherlands'\n",
       "13. 'Denmark'\n",
       "14. 'Poland'\n",
       "15. 'Germany'\n",
       "16. 'Russia'\n",
       "17. 'Syria'\n",
       "18. 'India'\n",
       "19. 'South Africa'\n",
       "20. 'Hong Kong'\n",
       "21. 'United Arab Emirates'\n",
       "22. 'Switzerland'\n",
       "23. 'Ireland'\n",
       "24. 'France'\n",
       "25. 'Jersey'\n",
       "26. 'Austria'\n",
       "27. 'New Zealand'\n",
       "28. 'Norway'\n",
       "29. 'Costa Rica'\n",
       "30. 'Mexico'\n",
       "31. 'Greece'\n",
       "32. 'Serbia and Montenegro'\n",
       "33. 'Cayman Islands'\n",
       "34. 'Philippines'\n",
       "35. 'Indonesia'\n",
       "36. 'Slovenia'\n",
       "37. 'Bulgaria'\n",
       "38. 'Guernsey'\n",
       "39. 'Iceland'\n",
       "40. 'Hungary'\n",
       "41. 'Bahrain'\n",
       "42. 'Thailand'\n",
       "43. 'Turkey'\n",
       "44. 'Moldova'\n",
       "45. 'Nicaragua'\n",
       "46. 'Lithuania'\n",
       "47. 'Portugal'\n",
       "48. 'Argentina'\n",
       "49. 'Finland'\n",
       "50. 'Israel'\n",
       "51. 'Slovakia'\n",
       "52. 'Pakistan'\n",
       "53. 'Luxembourg'\n",
       "54. 'Jamaica'\n",
       "55. 'Ukraine'\n",
       "56. 'Malta'\n",
       "57. 'Czech Republic'\n",
       "58. 'Colombia'\n",
       "59. 'Singapore'\n",
       "60. 'Jordan'\n",
       "61. 'Uganda'\n",
       "62. 'Belarus'\n",
       "63. 'Estonia'\n",
       "64. 'Puerto Rico'\n",
       "65. 'Saudi Arabia'\n",
       "66. 'Latvia'\n",
       "67. 'Malaysia'\n",
       "68. 'Nepal'\n",
       "69. 'Ghana'\n",
       "70. 'Dominican Republic'\n",
       "71. 'Uruguay'\n",
       "72. 'Guatemala'\n",
       "73. 'El Salvador'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"United States\"         \"Australia\"             \"Spain\"                \n",
       " [4] \"United Kingdom\"        \"Canada\"                \"Romania\"              \n",
       " [7] \"Brazil\"                \"Croatia\"               \"Sweden\"               \n",
       "[10] \"Belgium\"               \"Italy\"                 \"Netherlands\"          \n",
       "[13] \"Denmark\"               \"Poland\"                \"Germany\"              \n",
       "[16] \"Russia\"                \"Syria\"                 \"India\"                \n",
       "[19] \"South Africa\"          \"Hong Kong\"             \"United Arab Emirates\" \n",
       "[22] \"Switzerland\"           \"Ireland\"               \"France\"               \n",
       "[25] \"Jersey\"                \"Austria\"               \"New Zealand\"          \n",
       "[28] \"Norway\"                \"Costa Rica\"            \"Mexico\"               \n",
       "[31] \"Greece\"                \"Serbia and Montenegro\" \"Cayman Islands\"       \n",
       "[34] \"Philippines\"           \"Indonesia\"             \"Slovenia\"             \n",
       "[37] \"Bulgaria\"              \"Guernsey\"              \"Iceland\"              \n",
       "[40] \"Hungary\"               \"Bahrain\"               \"Thailand\"             \n",
       "[43] \"Turkey\"                \"Moldova\"               \"Nicaragua\"            \n",
       "[46] \"Lithuania\"             \"Portugal\"              \"Argentina\"            \n",
       "[49] \"Finland\"               \"Israel\"                \"Slovakia\"             \n",
       "[52] \"Pakistan\"              \"Luxembourg\"            \"Jamaica\"              \n",
       "[55] \"Ukraine\"               \"Malta\"                 \"Czech Republic\"       \n",
       "[58] \"Colombia\"              \"Singapore\"             \"Jordan\"               \n",
       "[61] \"Uganda\"                \"Belarus\"               \"Estonia\"              \n",
       "[64] \"Puerto Rico\"           \"Saudi Arabia\"          \"Latvia\"               \n",
       "[67] \"Malaysia\"              \"Nepal\"                 \"Ghana\"                \n",
       "[70] \"Dominican Republic\"    \"Uruguay\"               \"Guatemala\"            \n",
       "[73] \"El Salvador\"          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique(survey_2018$Country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'Full time employee'</li>\n",
       "\t<li>'Full time employee of a consulting/contracting company'</li>\n",
       "\t<li><span style=white-space:pre-wrap>'Independent consultant, contractor, freelancer,  or company owner'</span></li>\n",
       "\t<li>'Part time'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Full time employee'\n",
       "\\item 'Full time employee of a consulting/contracting company'\n",
       "\\item 'Independent consultant, contractor, freelancer,  or company owner'\n",
       "\\item 'Part time'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Full time employee'\n",
       "2. 'Full time employee of a consulting/contracting company'\n",
       "3. <span style=white-space:pre-wrap>'Independent consultant, contractor, freelancer,  or company owner'</span>\n",
       "4. 'Part time'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"Full time employee\"                                               \n",
       "[2] \"Full time employee of a consulting/contracting company\"           \n",
       "[3] \"Independent consultant, contractor, freelancer,  or company owner\"\n",
       "[4] \"Part time\"                                                        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique(survey_2018$EmploymentStatus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `setDT` function on `data.table` to see just how many records we have for each level of a particular factor.  For example, we can see the different entries for PrimaryDatabase and EmploymentSector below.  Both of these are troublesome for our modeling because they both have a number of levels with 1-2 entries.  This makes it likely that we will fail to collect a relevant record in our training data set, and that will mess up our model later.  To rectify this, I am going to remove PrimaryDatabase as a feature and remove the two students from our sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>PrimaryDatabase</th><th scope=col>N</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Amazon RDS (any flavor)</td><td>   5                   </td></tr>\n",
       "\t<tr><td>Azure SQL DB           </td><td>  13                   </td></tr>\n",
       "\t<tr><td>Cassandra              </td><td>   1                   </td></tr>\n",
       "\t<tr><td>DB2                    </td><td>   9                   </td></tr>\n",
       "\t<tr><td>Microsoft Access       </td><td>   9                   </td></tr>\n",
       "\t<tr><td>Microsoft SQL Server   </td><td>2914                   </td></tr>\n",
       "\t<tr><td>MongoDB                </td><td>   3                   </td></tr>\n",
       "\t<tr><td>MySQL/MariaDB          </td><td>  15                   </td></tr>\n",
       "\t<tr><td>Oracle                 </td><td> 105                   </td></tr>\n",
       "\t<tr><td>Other                  </td><td>  14                   </td></tr>\n",
       "\t<tr><td>PostgreSQL             </td><td>  17                   </td></tr>\n",
       "\t<tr><td>SAP                    </td><td>   2                   </td></tr>\n",
       "\t<tr><td>SQLite                 </td><td>   3                   </td></tr>\n",
       "\t<tr><td>Teradata               </td><td>   3                   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " PrimaryDatabase & N\\\\\n",
       "\\hline\n",
       "\t Amazon RDS (any flavor) &    5                   \\\\\n",
       "\t Azure SQL DB            &   13                   \\\\\n",
       "\t Cassandra               &    1                   \\\\\n",
       "\t DB2                     &    9                   \\\\\n",
       "\t Microsoft Access        &    9                   \\\\\n",
       "\t Microsoft SQL Server    & 2914                   \\\\\n",
       "\t MongoDB                 &    3                   \\\\\n",
       "\t MySQL/MariaDB           &   15                   \\\\\n",
       "\t Oracle                  &  105                   \\\\\n",
       "\t Other                   &   14                   \\\\\n",
       "\t PostgreSQL              &   17                   \\\\\n",
       "\t SAP                     &    2                   \\\\\n",
       "\t SQLite                  &    3                   \\\\\n",
       "\t Teradata                &    3                   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "PrimaryDatabase | N | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| Amazon RDS (any flavor) |    5                    | \n",
       "| Azure SQL DB            |   13                    | \n",
       "| Cassandra               |    1                    | \n",
       "| DB2                     |    9                    | \n",
       "| Microsoft Access        |    9                    | \n",
       "| Microsoft SQL Server    | 2914                    | \n",
       "| MongoDB                 |    3                    | \n",
       "| MySQL/MariaDB           |   15                    | \n",
       "| Oracle                  |  105                    | \n",
       "| Other                   |   14                    | \n",
       "| PostgreSQL              |   17                    | \n",
       "| SAP                     |    2                    | \n",
       "| SQLite                  |    3                    | \n",
       "| Teradata                |    3                    | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   PrimaryDatabase         N   \n",
       "1  Amazon RDS (any flavor)    5\n",
       "2  Azure SQL DB              13\n",
       "3  Cassandra                  1\n",
       "4  DB2                        9\n",
       "5  Microsoft Access           9\n",
       "6  Microsoft SQL Server    2914\n",
       "7  MongoDB                    3\n",
       "8  MySQL/MariaDB             15\n",
       "9  Oracle                   105\n",
       "10 Other                     14\n",
       "11 PostgreSQL                17\n",
       "12 SAP                        2\n",
       "13 SQLite                     3\n",
       "14 Teradata                   3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.table::setDT(survey_2018)[, .N, keyby=PrimaryDatabase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>EmploymentSector</th><th scope=col>N</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Education (K-12, college, university)</td><td> 123                                 </td></tr>\n",
       "\t<tr><td>Federal government                   </td><td>  76                                 </td></tr>\n",
       "\t<tr><td>Local government                     </td><td> 118                                 </td></tr>\n",
       "\t<tr><td>Non-profit                           </td><td> 165                                 </td></tr>\n",
       "\t<tr><td>Private business                     </td><td>2498                                 </td></tr>\n",
       "\t<tr><td>State/province government            </td><td> 131                                 </td></tr>\n",
       "\t<tr><td>Student                              </td><td>   2                                 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " EmploymentSector & N\\\\\n",
       "\\hline\n",
       "\t Education (K-12, college, university) &  123                                 \\\\\n",
       "\t Federal government                    &   76                                 \\\\\n",
       "\t Local government                      &  118                                 \\\\\n",
       "\t Non-profit                            &  165                                 \\\\\n",
       "\t Private business                      & 2498                                 \\\\\n",
       "\t State/province government             &  131                                 \\\\\n",
       "\t Student                               &    2                                 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "EmploymentSector | N | \n",
       "|---|---|---|---|---|---|---|\n",
       "| Education (K-12, college, university) |  123                                  | \n",
       "| Federal government                    |   76                                  | \n",
       "| Local government                      |  118                                  | \n",
       "| Non-profit                            |  165                                  | \n",
       "| Private business                      | 2498                                  | \n",
       "| State/province government             |  131                                  | \n",
       "| Student                               |    2                                  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  EmploymentSector                      N   \n",
       "1 Education (K-12, college, university)  123\n",
       "2 Federal government                      76\n",
       "3 Local government                       118\n",
       "4 Non-profit                             165\n",
       "5 Private business                      2498\n",
       "6 State/province government              131\n",
       "7 Student                                  2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.table::setDT(survey_2018)[, .N, keyby=EmploymentSector]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of these columns came from dropdown lists, so they're already fairly clean.  But there are some exceptions to the rule.  They are:\n",
    "* SalaryUSD\n",
    "* YearsWithThisDatabase\n",
    "* YearsWithThisTypeOfJob\n",
    "* DatabaseServers\n",
    "* HoursWorkedPerWeek\n",
    "* Gender\n",
    "\n",
    "All of these were text fields, and whenever a user gets to enter text, you can assume that something will go wrong.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_2018 %>%\n",
    "  distinct(YearsWithThisDatabase) %>%\n",
    "  arrange(desc(YearsWithThisDatabase)) %>%\n",
    "  top_n(10, YearsWithThisDatabase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Someone with 53,716 years working with their primary database of choice?  That's committment!  You can also see a couple of people who clearly put in the year they started rather htan the number of years working with it, and someone who maybe meant 10 years?  But who knows, people type in weird stuff.\n",
    "\n",
    "Anyhow, let's see how much that person with at least 10 thousand years of experience makes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_2018 %>%\n",
    "  filter(YearsWithThisDatabase > 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty sad, considering their millennia of work experience.  $95-98K isn't even that great a number.\n",
    "\n",
    "Looking at years of experience with their current job roles, people tend to be more reasonable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_2018 %>%\n",
    "  distinct(YearsWithThisTypeOfJob) %>%\n",
    "  arrange(desc(YearsWithThisTypeOfJob)) %>%\n",
    "  top_n(10, YearsWithThisTypeOfJob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, we want to look at the number of database servers owned.  500,000+ database servers is a bit excessive.  Frankly, I'm suspicious about any numbers greater than 5000, but because I can't prove it otherwise, I'll leave them be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_2018 %>%\n",
    "  distinct(DatabaseServers) %>%\n",
    "  arrange(desc(DatabaseServers)) %>%\n",
    "  top_n(10, DatabaseServers)\n",
    "\n",
    "survey_2018 %>%\n",
    "  filter(DatabaseServers >= 5000) %>%\n",
    "  arrange(desc(DatabaseServers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first entry looks like bogus data:  a $650K salary, a matching postal code, and 500K database servers, primarily in RDS?  Nope, I don't buy it.\n",
    "\n",
    "The rest don't really look out of place, except that I think they put in the number of **databases** and not **servers**.  For these entrants, I'll change the number of servers to the median to avoid distorting things.\n",
    "\n",
    "Now let's look at hours per week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_2018 %>%\n",
    "  distinct(HoursWorkedPerWeek) %>%\n",
    "  arrange(desc(HoursWorkedPerWeek)) %>%\n",
    "  top_n(10, HoursWorkedPerWeek)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To the person who works 200 hours per week:  find a new job.  Your ability to pack more than 7\\*24 hours of work into 7 days is too good to waste on a job making just $120K per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_2018 %>%\n",
    "  filter(HoursWorkedPerWeek >= 168) %>%\n",
    "  arrange(desc(HoursWorkedPerWeek))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as Gender goes, there are only three with enough records to be significant:  Male, Female, and Prefer not to say.  We'll take Male and Female and bundle the rest under \"Other\" to get a small but not entirely insignificant set there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_2018 %>%\n",
    "  group_by(Gender) %>%\n",
    "  summarize(n = n())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_2018 %>%\n",
    "  group_by(Country) %>%\n",
    "  summarize(n = n()) %>%\n",
    "  filter(n >= 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only fifteen countries with at least 20 data points and just eight with at least 30.  This means that we won't get a great amount of information from cross-country comparisons outside of the sample.  Frankly, I might want to limit this to just the US, UK, Canada, and Australia, as the rest are marginal, but for this survey analysis, I'll keep the other eleven."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Our Cleaned-Up Data Set\n",
    "\n",
    "Now that we've performed some basic analysis, we will clean up the data set.  I'm doing most of the cleanup in a single operation, but I do have some comment notes here, particularly around the oddities with SalaryUSD.  The SalaryUSD column has a few problems:\n",
    "* Some people put in pennies, which aren't really that important at the level we're discussing.  I want to strip them out.\n",
    "* Some people put in delimiters like commas or decimal points (which act as commas in countries like Germany).  I want to strip them out, particularly because the decimal point might interfere with my analysis, turning 100.000 to $100 instead of $100K.\n",
    "* Some people included the dollar sign, so remove that, as well as any spaces.\n",
    "\n",
    "It's not a perfect regex, but it did seem to fix the problems in this data set at least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_countries <- survey_2018 %>%\n",
    "                    group_by(Country) %>%\n",
    "                    summarize(n = n()) %>%\n",
    "                    filter(n >= 20)\n",
    "\n",
    "# Data cleanup\n",
    "survey_2018 <- salary_data %>%\n",
    "  filter(Survey.Year == 2018) %>%\n",
    "  filter(HoursWorkedPerWeek < 200) %>%\n",
    "  # There were only two students in the survey, so we will exclude them here.\n",
    "  filter(EmploymentSector != \"Student\") %>%\n",
    "  inner_join(valid_countries, by=\"Country\") %>%\n",
    "  mutate(\n",
    "    SalaryUSD = stringr::str_replace_all(SalaryUSD, \"\\\\$\", \"\") %>%\n",
    "      stringr::str_replace_all(., \",\", \"\") %>%\n",
    "      stringr::str_replace_all(., \" \", \"\") %>%\n",
    "      # Some people put in pennies.  Let's remove anything with a decimal point and then two numbers.\n",
    "      stringr::str_replace_all(., stringr::regex(\"\\\\.[0-9]{2}$\"), \"\") %>%\n",
    "      # Now any decimal points remaining are formatting characters.\n",
    "      stringr::str_replace_all(., \"\\\\.\", \"\") %>%\n",
    "      as.numeric(.),\n",
    "    # Some people have entered bad values here, so set them to the median.\n",
    "    YearsWithThisDatabase = case_when(\n",
    "      (YearsWithThisDatabase > 32) ~ median(YearsWithThisDatabase),\n",
    "      TRUE ~ YearsWithThisDatabase\n",
    "    ),\n",
    "    # Some people apparently entered number of databases rather than number of servers.\n",
    "    DatabaseServers = case_when(\n",
    "      (DatabaseServers >= 5000) ~ median(DatabaseServers),\n",
    "      TRUE ~ DatabaseServers\n",
    "    ),\n",
    "    EmploymentStatus = as.factor(EmploymentStatus),\n",
    "    JobTitle = as.factor(JobTitle),\n",
    "    ManageStaff = as.factor(ManageStaff),\n",
    "    OtherPeopleOnYourTeam = as.factor(OtherPeopleOnYourTeam),\n",
    "    Education = as.factor(Education),\n",
    "    EducationIsComputerRelated = as.factor(EducationIsComputerRelated),\n",
    "    Certifications = as.factor(Certifications),\n",
    "    TelecommuteDaysPerWeek = as.factor(TelecommuteDaysPerWeek),\n",
    "    EmploymentSector = as.factor(EmploymentSector),\n",
    "    LookingForAnotherJob = as.factor(LookingForAnotherJob),\n",
    "    CareerPlansThisYear = as.factor(CareerPlansThisYear),\n",
    "    Gender = as.factor(case_when(\n",
    "      (Gender == \"Male\") ~ \"Male\",\n",
    "      (Gender == \"Female\") ~ \"Female\",\n",
    "      TRUE ~ \"Other\"\n",
    "    ))\n",
    "  ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pare out variables we don't need.  Some of these, like postal code, are interesting but we just don't have enough data for it to make sense.  Others, like Kinds of Tasks Performed or Other Job Duties, have too many varieties for us to make much sense with a first pass.  They might be interesting in a subsequent analysis, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_2018 <- survey_2018 %>%\n",
    "  # One person had a salary of zero.  That's just not right.\n",
    "  filter(SalaryUSD > 0) %>%\n",
    "  select(-Counter, -KindsOfTasksPerformed, -OtherJobDuties, -OtherDatabases, -Timestamp, -Survey.Year, \n",
    "         -PostalCode, -n, -PrimaryDatabase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our salary data fixed, we can finally look at outliers.  I'd consider a salary of \\$500K a year to be a bit weird for this field.  It's not impossible, but I am a little suspicious.  I am very suspicious of the part-timer making \\$1.375 million, the federal employee making \\$1 million, or the New Zealander making \\$630K at a non-profit.\n",
    "\n",
    "I'm kind of taking a risk by removing these, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_2018 %>%\n",
    "  filter(SalaryUSD > 500000) %>%\n",
    "  arrange(desc(SalaryUSD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other side, there are 12 people who say they earned less than $5K a year.  Those also seem wrong.  Some of them look like dollars per  hour, and maybe some are monthly salary.  I'm going to strip those out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_2018 %>%\n",
    "  filter(SalaryUSD < 5000) %>%\n",
    "  arrange(desc(SalaryUSD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_2018 <- filter(survey_2018, SalaryUSD >= 5000 & SalaryUSD <= 500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "\n",
    "We did some of the data analysis up above.  We can do additional visualization and correlation studies.  For example, let's look at a quick distribution of salaries after our cleanup work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(survey_2018$SalaryUSD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also build a histogram pretty easily using the `ggplot2` library.  This shows the big clump of database professionals earning beween \\$70K and \\$115K per year.  This salary distribution does skew right a bit, as you can see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data = survey_2018, mapping = aes(x = SalaryUSD)) +\n",
    "  geom_histogram() +\n",
    "  theme_minimal() +\n",
    "  scale_x_log10(label = scales::dollar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also break this down to look by primary job title, though I'll limit to a couple of summaries instead of showing a full picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_2018 %>% filter(JobTitle == \"Data Scientist\") %>% select(SalaryUSD) %>% summary(.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_2018 %>% filter(JobTitle == \"Developer: App code (C#, JS, etc)\") %>% select(SalaryUSD) %>% summary(.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_2018 %>% filter(JobTitle == \"Developer: T-SQL\") %>% select(SalaryUSD) %>% summary(.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fit pretty well to my biases, although the max Data Scientist salary seems rather low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Because our question is a \"how much?\" question, we want to use regression to solve the problem.  The most common form of regression that you'll see in demonstrations is linear regression, because it is easy to teach and easy to understand.  In today's demo, however, we're going to build a neural network with Keras.  Although our demo is in R, Keras actually uses Python on the back end to run TensorFlow.  There are other libraries out there which can run neural networks strictly within R (for example, Microsoft Machine Learning's R implemenation has the `RxNeuralNet()` function), but we will use Keras in this demo because it is a popular library.\n",
    "\n",
    "Now that we have an algorithm and implementation in mind, let's split the data out into training and test subsets.  I want to use Country as the partition variable because I want to ensure that we retain some data from each country in the test set.  To make this split, I am using the `createDataPartition()` function in `caret`.  I'll then split out the data into training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIndex <- caret::createDataPartition(survey_2018$Country, p = 0.7, list = FALSE, times = 1)\n",
    "train_data <- survey_2018[trainIndex,]\n",
    "test_data <- survey_2018[-trainIndex,]\n",
    "nrow(train_data)\n",
    "nrow(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once I have this data split, I want to perform some operations on the training data.  Specifically, I want to do the following:\n",
    "* One-Hot Encode the categorical data\n",
    "* Mean-center the data, so that the mean of each numeric value is 0\n",
    "* Scale the data, so that the standard deviation of each value is 1\n",
    "\n",
    "The bottom two are called **normalizing** the data.  This is a valuable technique when dealing with many algorithms, including neural networks, as it helps with optimizing gradient descent problems.\n",
    "\n",
    "In order to perform all of these operations, I will create a `recipe`, using the `recipes` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data Recipe\n",
       "\n",
       "Inputs:\n",
       "\n",
       "      role #variables\n",
       "   outcome          1\n",
       " predictor         17\n",
       "\n",
       "Training data contained 1976 data points and no missing data.\n",
       "\n",
       "Operations:\n",
       "\n",
       "Dummy variables from Country, EmploymentStatus, JobTitle, ... [trained]\n",
       "Centering for YearsWithThisDatabase, ... [trained]\n",
       "Scaling for YearsWithThisDatabase, ... [trained]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rec_obj <- recipes::recipe(SalaryUSD ~ ., data = train_data) %>%       # Build out a set of rules we want to follow (a recipe)\n",
    "  step_dummy(all_nominal(), -all_outcomes()) %>%              # One-hot encode categorical data\n",
    "  step_center(all_predictors(), -all_outcomes()) %>%          # Mean-center the data\n",
    "  step_scale(all_predictors(), -all_outcomes()) %>%           # Scale the data\n",
    "  prep(data = train_data)\n",
    "\n",
    "rec_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can `bake` our data based on the recipe above.  Note that I performed all of these operations only on the **training** data.  If we normalize the training + test data, our optimization function can get a sneak peek at the distribution of the test data based on what is in the training set, and that will bias our result.\n",
    "\n",
    "After building up the `x_` series of data sets, I'll build vectors which contain the salaries for the training and test data.  I need to make sure to remove the SalaryUSD variable; we don't want to make that available to the trainer as an independent variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data <- recipes::bake(rec_obj, newdata = train_data)\n",
    "x_test_data <- recipes::bake(rec_obj, newdata = test_data)\n",
    "y_train_vec <- pull(x_train_data, SalaryUSD)\n",
    "y_test_vec  <- pull(x_test_data, SalaryUSD)\n",
    "# Remove the SalaryUSD variable.\n",
    "x_train_data <- x_train_data[,-1]\n",
    "x_test_data <- x_test_data[,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, I want to build the Keras model.  I'm creating a `build_model` function in case I want to run this over and over. In a real-life scenario, I would perform various optimizations, do cross-validation, etc.  In this scenario, however, I am just going to run one time against the full training data set, and then evaluate it against the test data set.\n",
    "\n",
    "Inside the function, we start by declaring a Keras model.  Then, I add three layers to the model.  The first layer is a dense (fully-connected) layer which accepts the training data as inputs and uses the Rectified Linear Unit (ReLU) activation mechanism.  This is a decent first guess for activation mechanisms.  We then have a dropout layer, which reduces the risk of overfitting on the training data.  Finally, I have a dense layer for my output, which will give me the salary.\n",
    "\n",
    "I compile the model using the `RMSProp` optimizer.  This is a good default optimizer for neural networks, although you might try `Adagrad`, `Adam`, or `AdaMax` as well.  Our loss function is Mean Squared Error, which is good for dealing with finding the error in a regression.  Finally, I'm interested in the Mean Absolute Error--that is, the dollar amount difference between our function's prediction and the actual salary.  The closer to \\$0 this is, the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model <- function() {\n",
    "  model <- keras_model_sequential() %>%\n",
    "    layer_dense(units = ncol(x_train_data), input_shape = c(ncol(x_train_data)), activation = \"relu\") %>%\n",
    "    layer_dropout(rate = 0.05) %>%\n",
    "    layer_dense(units = 1) # No activation --> linear layer\n",
    "\n",
    "  # RMSProp is a nice default optimizer for a neural network.\n",
    "  # Mean Squared Error is a classic loss function for dealing with regression-style problems, whether with a neural network or otherwise.\n",
    "  # Mean Average Error gives us a metric which directly translates to the number of dollars we are off with our predictions.\n",
    "  model %>% compile(\n",
    "    optimizer = \"rmsprop\",\n",
    "    loss = \"mse\",\n",
    "    metrics = c(\"mae\")\n",
    "  )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building out this model can take some time, so be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$loss</dt>\n",
       "\t\t<dd>9911862777.30321</dd>\n",
       "\t<dt>$mean_absolute_error</dt>\n",
       "\t\t<dd>92376.9584479043</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$loss] 9911862777.30321\n",
       "\\item[\\$mean\\_absolute\\_error] 92376.9584479043\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$loss\n",
       ":   9911862777.30321\n",
       "$mean_absolute_error\n",
       ":   92376.9584479043\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$loss\n",
       "[1] 9911862777\n",
       "\n",
       "$mean_absolute_error\n",
       "[1] 92376.96\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model <- build_model()\n",
    "model %>% fit(as.matrix(x_train_data), y_train_vec, epochs = 30, batch_size = 16, verbose = 0)\n",
    "result <- model %>% evaluate(as.matrix(x_test_data), y_test_vec)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
